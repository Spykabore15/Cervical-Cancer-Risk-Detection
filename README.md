# ğŸ“Š Cervical Cancer Detection â€“ End-to-End ML Pipeline  

**ğŸ“ EFREI Paris | Author: JuvÃ©nis KaborÃ©**  
ğŸ§  *Predicting cervical cancer risk using machine learning and Microsoft Fabric orchestration.*

---

## ğŸ“Œ Project Overview  

This project develops a complete **end-to-end machine learning pipeline** for predicting **cervical cancer** based on clinical and behavioral risk factors.  

The pipeline is **built and orchestrated in Microsoft Fabric** with **Git integration**, ensuring full reproducibility, automation, and version control across all stages of the workflow.  

### ğŸ”‘ Key Steps
- **Data preprocessing** using **Dataflow Gen2 (Dataflow 2)**  
- **Exploratory Data Analysis (EDA)** & model benchmarking in a dedicated research notebook  
- **Final orchestrated pipeline** combining Dataflow preprocessing and CatBoost model training  
- **Deployment-ready model export** for integration into downstream applications  

---

## ğŸ“‚ Repository & Workspace Structure  

â”œâ”€â”€ Dataflow_2/ # Dataflow Gen2 pipeline (data preprocessing)
â”‚ â””â”€â”€ cervical_cancer_data_cleaned # Cleaned dataset (output)
â”œâ”€â”€ data_training_notebook.py # Research notebook: EDA, feature selection, model comparison
â”œâ”€â”€ Final_notebook.py # Final deployable ML model (CatBoost)
â”œâ”€â”€ Final_pipeline/ # Data pipeline orchestration
â”‚ â”œâ”€â”€ Dataflow_2 # Executes preprocessing
â”‚ â””â”€â”€ Final_notebook.py # Runs final model training & saving
â””â”€â”€ README.md # Project documentation


---

## ğŸ§­ Microsoft Fabric Workspace: `cancer_detection_analysis`

âœ… **Dataflow** â€“ ETL & data cleaning  
âœ… **Notebooks** â€“ Training and final model pipeline  
âœ… **Pipeline** â€“ End-to-end orchestration  
âœ… **Lakehouse** â€“ Unified storage & analytics layer  
âœ… **Git Integration** â€“ Version control & collaboration  

---

## âš™ï¸ Workflow  

### 1ï¸âƒ£ Data Preprocessing â€“ *Dataflow Gen2*  
Data ingestion and cleaning performed through Fabricâ€™s **Dataflow Gen2**.  
**Steps include:**  
- Handling missing values  
- Filtering outliers  
- Feature normalization and schema validation  
- Exporting the cleaned dataset (`cervical_cancer_data_cleaned`) to **Lakehouse**

---

### 2ï¸âƒ£ Model Development â€“ *Research Notebook*  
- Conducted **Exploratory Data Analysis (EDA)** with `Pandas`, `Seaborn`, and `Matplotlib`.  
- Performed **feature selection** using `RandomForest` + `SelectFromModel`.  
- Managed **class imbalance** via `SMOTE`, `ADASYN`, and `RandomOverSampler`.  
- Benchmarked multiple models: `RandomForest`, `XGBoost`, `CatBoost`, and `SVM`.  
- Used **SHAP values** for feature importance and interpretability.  
- **Result:** `CatBoostClassifier` selected as the **final model** for its superior performance and explainability.  

---

### 3ï¸âƒ£ Final Pipeline â€“ *Fabric Orchestration*  
A complete **Fabric pipeline** was developed to automate the full ML workflow:  

**Pipeline sequence:**  
1. Dataflow â†’ Cleans and pre-processes the data  
2. Notebook â†’ Trains and evaluates the CatBoost model  


**Best Model:** `CatBoostClassifier`  
**Interpretability:** SHAP values highlighted critical risk factors including *Age*, *Number of pregnancies*, *Smoking history*, and *HPV test results*.  

---

## ğŸš€ Deployment  

The final model (`.cbm` format) is **deployment-ready** and can be integrated into:  
- ğŸŒ **REST APIs** (Flask / FastAPI)  
- ğŸ“ˆ **Clinical dashboards** for healthcare analytics  
- â˜ï¸ **Batch inference pipelines** in Azure ML / Fabric  

---

## ğŸ”§ Tech Stack  

| Category | Tools & Frameworks |
|-----------|--------------------|
| Platform | Microsoft Fabric (Dataflow Gen2, Pipelines, Lakehouse, Git Integration) |
| Language | Python |
| Libraries | pandas, scikit-learn, imbalanced-learn, xgboost, catboost, shap |
| Visualization | matplotlib, seaborn |
| MLOps | Git integration, automated Fabric pipelines |

---

## ğŸ“Œ Next Steps  

- Parameters tunning
- ğŸ³ Containerize the final pipeline with **Docker + Azure ML**  
- ğŸ” Automate retraining and monitoring via **Fabric Pipelines (MLOps best practices)**  
- ğŸ§ª Validate model performance on **external datasets** for robustness  
- ğŸŒ Develop a **real-time inference API** for clinical deployment  

---

## ğŸ§  Key Learnings  

- Building modular **end-to-end ML pipelines** using cloud-native tools  
- Applying **data engineering principles** in healthcare data processing  
- Balancing model accuracy, interpretability, and automation  
- Leveraging **Microsoft Fabric** for reproducible and scalable ML workflows  

---

## ğŸ‘¤ Author  

**JuvÃ©nis KaborÃ©**  
ğŸ“ Data Engineering & AI Student â€“ EFREI Paris  
ğŸ“ Currently in Malaysia | Passionate about AI, MLOps, and cloud data platforms  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/fortune-kabore) â€¢ [GitHub](https://github.com/Spykabore15)

---

â­ *â€œData becomes powerful when it drives meaningful change.â€*

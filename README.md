# ğŸ“ˆ Cervical Cancer Risk Detection â€” End-to-End ML Pipeline

**Author:** JuvÃ©nis KaborÃ©  
EFREI Paris | Data Engineering & AI Student  
ğŸŒ Currently in Malaysia  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/fortune-kabore) â€¢ [GitHub](https://github.com/Spykabore15)

---

## ğŸ©º Project Overview

This repository provides a robust **end-to-end machine learning pipeline** for predicting **cervical cancer risk** using clinical and behavioral factors. The pipeline leverages **Microsoft Fabric** for orchestration and reproducibility, integrates with Git for version control, and is built with production readiness in mind.

### Key Features
- **Modular cloud-native workflow**: ETL, modeling, and deployment stages are clearly separated & automated.
- **Clinical interpretability**: Integration of SHAP for explaining model decisions.
- **Deployment ready**: Exported CatBoost model compatible with API, dashboard, and pipeline integration.

---

## ğŸ—‚ï¸ Repository Structure

```plaintext
Cervical-Cancer-Risk-Detection/
â”œâ”€â”€ Dataflow_2/                   # Data preprocessing with Dataflow Gen2
â”‚   â””â”€â”€ cervical_cancer_data_cleaned  # Clean dataset (output)
â”œâ”€â”€ data_training_notebook.py     # Research notebook (EDA, feature selection, model benchmarking)
â”œâ”€â”€ Final_notebook.py             # Production notebook (CatBoost training + export)
â”œâ”€â”€ Final_pipeline/               # Fabric orchestration scripts
â”‚   â”œâ”€â”€ Dataflow_2                # ETL execution
â”‚   â””â”€â”€ Final_notebook.py         # Model training & registry
â””â”€â”€ README.md                     # Documentation
```

---

## ğŸ–¥ï¸ Microsoft Fabric Workspace: `cancer_detection_analysis`

- **Dataflow** â€” ETL & Data Cleaning
- **Notebooks** â€” Research, training, and deployment pipeline
- **Pipeline** â€” Workflow automation within Fabric
- **Lakehouse** â€” Unified storage for analytics and models
- **Git Integration** â€” Collaboration & version control

---

## âš™ï¸ End-to-End Workflow

### 1ï¸âƒ£ Data Preprocessing (Dataflow Gen2)
- Missing value handling
- Outlier filtering
- Feature normalization & schema validation
- Exporting cleaned dataset to Lakehouse

### 2ï¸âƒ£ Model Development (Research Notebook)
- **EDA**: Visualization of risk factors with pandas, seaborn, matplotlib
- **Feature selection:** RandomForest + SelectFromModel
- **Class imbalance:** SMOTE, ADASYN, RandomOverSampler (imbalanced-learn)
- **Model comparison:** RandomForest, XGBoost, CatBoost, SVM
- **Interpretability:** SHAP values for important features
- **Outcome:** `CatBoostClassifier` selected for performance & explainability

### 3ï¸âƒ£ Pipeline Orchestration (Fabric)
- **Automation:** Microsoft Fabric orchestrates ETL + model training + registry in one pipeline
- **Sequence:** Dataflow â†’ Notebook (training) â†’ Export model

---

## ğŸ¤– ML Model & Deployment

- **Best Model:** CatBoostClassifier (.cbm format)
- **Key features:** Age, Number of pregnancies, Smoking history, HPV test results, etc.
- **Interpretability:** SHAP plots highlight feature contribution (see notebooks for examples)
- **Integration options:**
    - ğŸŸ¢ REST APIs (Flask, FastAPI)
    - ğŸŸ£ Clinical dashboards
    - â˜ï¸ Azure ML or Microsoft Fabric batch inference

---

## ğŸ› ï¸ Tech Stack

| Category | Tools & Frameworks |
|----------|--------------------|
| Platform | Microsoft Fabric (Dataflow Gen2, Pipelines, Lakehouse, Git Integration) |
| Language | Python |
| Libraries | pandas, scikit-learn, imbalanced-learn, xgboost, catboost, shap |
| Visualization | matplotlib, seaborn |
| MLOps | Git integration, automated Fabric pipelines |

---

## ğŸš€ Quickstart

### Prerequisites
- Python 3.8+
- Access to Microsoft Fabric workspace with Dataflow, Lakehouse, and Pipeline capabilities

### Setup

```bash
# Clone repository
git clone https://github.com/Spykabore15/Cervical-Cancer-Risk-Detection.git

# (Optional) Set up Python environment
python3 -m venv .venv
source .venv/bin/activate
pip install pandas scikit-learn imbalanced-learn xgboost catboost shap matplotlib seaborn

# Follow notebooks in order (EDA â†’ feature selection â†’ modeling â†’ export)
# See Dataflow_2/ for preprocessing logic
```

### Running Model Training

1. Execute `Dataflow_2` for cleansing and export data to Lakehouse.
2. Open `data_training_notebook.py` and work through EDA, feature selection, class imbalance, and model benchmarking.
3. Use `Final_notebook.py` for CatBoost model training and export.
4. Exported models can be integrated into APIs, dashboards, or batch inference pipelines.

---

## ğŸ§ª Testing

- **Validation:** Accuracy, F1, confusion matrix, ROC-AUC reported in research/model notebooks.
- **Robustness:** Next steps include testing with external datasets, monitoring, and continuous retraining via MLOps.

---

## ğŸ““ Example Results

Feature Importance Example (SHAP plot):
```
Top features: Age, NumOfPregnancies, SmokesPacksYear, DxCancer, HPV related
Model: CatBoostClassifier
See `Final_notebook.py` / SHAP summary plots for explainability
```

Sample performance:
- F1 score (cross-validated): *provided in confusion matrices in notebooks*
- Interpretability: *SHAP values and EDA shown in included notebooks*

---

## ğŸ“‹ Next Steps

- Hyperparameter tuning and model selection refinement
- ğŸ³ Containerization with Docker + Azure ML
- ğŸ” Automated retraining & drift monitoring
- ğŸ§‘â€âš•ï¸ Real-time API for clinical application

---

## ğŸ‘¨â€ğŸ’» Author

**JuvÃ©nis KaborÃ©**
EFREI Paris â€” Data Engineering & AI Student
ğŸŒ [LinkedIn](https://www.linkedin.com/in/fortune-kabore) â€¢ [Portfolio](https://juvenis.lovable.app/)

*â€œData becomes powerful when it drives meaningful change.â€*
